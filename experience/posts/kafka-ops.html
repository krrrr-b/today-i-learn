<!DOCTYPE html>
<html lang="kr">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="krr-b 기술블로그">
  <meta name="author" content="krr-b">
  <title>민웅이서점</title>

  <link href="https://github.com/krrrr-b/today-i-learn/blob/main/experience/assets/css/bootstrap.min.css" rel="stylesheet">
  <link href="../css/one-page-wonder.min.css" rel="stylesheet">
  <link rel="stylesheet" type="text/css" crossorigin="anonymous" href="http://meta-kage.kakaocdn.net/dn/osa/blog/assets/fonts/Kakao.css"/>
  <link rel="stylesheet" type="text/css" crossorigin="anonymous" href="http://meta-kage.kakaocdn.net/dn/osa/blog/assets/fonts/SpoqaHanSans.css"/>

  <style>
    a {
      color: #000;
      text-decoration: none !important;
    }

    a:hover {
      color: #5F00FF;
    }

    .container {
      font-family: 'Spoqa Han Sans' !important, sans-serif;
      font-weight: lighter;
    }

    h2.display-5 {
      font-family: 'Kakao' !important, sans-serif;
      font-weight: lighter;
    }

    .kakao {
      font-family: 'Kakao' !important, sans-serif;
      font-weight: lighter;
    }

    .spoqa {
      font-family: 'Spoqa Han Sans' !important, sans-serif; 
      font-weight: lighter !important;
    }

    .spoqa-bold {
      font-family: 'Spoqa Han Sans' !important, sans-serif; 
      font-weight: bold !important;
    }

    .code {
      background-color: #5d5d5d;
      color: #FFF;

      font-family: 'Kakao' !important, sans-serif;
      font-weight: lighter !important;
    }

  </style>
</head>

<body style="width: 1076px !important; margin-right: 15% !important; margin-left: 15% !important;">

  <nav class="navbar navbar-expand-lg navbar-dark navbar-custom fixed-top" style="margin-right: 15% !important; margin-left: 15% !important; width: 1076px !important">
    <div class="container">
      <a class="navbar-brand spoqa" href="https://krr-b.github.io">민웅이서점</a>
    </div>
  </nav>

  <header class="masthead text-center text-white" style="background-image: url(../notebook.jpg);">
    <div class="masthead-content">
      <div class="container">
        <h1 class="masthead-heading mb-0 spoqa">KAFKA 운영</h1>
      </div>
    </div>
  </header>

  <section>
    <div class="container" style="margin-top: 50px; margin-bottom: 300px;">
      <h4>kafka reference: <a href="https://kafka.apache.org/" target="_blank">https://kafka.apache.org/</a></h4><br/>
      <h4>kafka 이론 정리: <a href="https://krr-b.github.io/posts/kafka.html" target="_blank">kafka 이론 정리</a>
      <br/><br/>
      <hr>  
      <br/>
      <h4>카프카 서버 구축 주의사항</h4>
      <br/>
      <blockquote cite="https://www.popit.kr/author/peter5236">
        <b>주키퍼 (분산 어플리케이션을 위한 코디네이션 시스템) 는 카프카의 노드 관리를 해주고, 토픽의 offset 정보등을 저장하기 위해 필요</b>합니다.<br/>
        <b>주키퍼는 과반수 투표방식으로 결정하기 때문에 홀수로 구성해야 하고, 과반수 이상 살아 있으면 정상으로 동작</b>합니다.<br/><br/>
        
        <b>ex. 주키퍼 3대일 경우 2대 이상, 주키퍼 5대일 경우 3대 이상</b><br/>
        (elasticsearch 방식과 동일)<br/>
        <br/>

        카프카는 과반수 투표방식을 사용하지 않지만,<br/>
        <b>Replication Factor를 3으로 할 경우 균일하게 스프레드하기 위해서 노드 수 3이 최소</b>라고 생각합니다.<br/>
        (__consumer_offsets 토픽은 기본값이 RF3)<br/>
        <br/>

        <b>서버를 시작할때, 주키퍼 부터 시작해야 합니다. 주키퍼가 카프카의 노드 관리를 하기 때문</b>입니다.<br/>
        <br/>

        카프카에서 토픽은 데이터베이스의 table 정도의 개념으로 생각하시면 될 것 같습니다.<br/>
        카프카에 저장되는 데이터를 토픽이라는 이름으로 구분하기 위해서 사용합니다.<br/>
        <br/>

        replica 2 or 3은 2개 or 3개로 복제할것인지를 의미하고, partition은 토픽을 몇개로 나눌지를 의미합니다.<br/>
        > bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test<br/>
        <br/>

        토픽이 생성되어 있는지 확인 합니다.<br/>
        > bin/kafka-topics.sh --list --zookeeper localhost:2181<br/>
        (consumer_offsets는 offset을 주키퍼가 아닌 카프카의 토픽으로 저장할때 사용하는 토픽이며, 자동으로 생성되는 토픽)<br/>
        <br/>

      </blockquote>
      <hr><br/>

      <h4>카프카 설치</h4>
      <br/>
      <kbd>
        sudo apt-get update && sudo apt-get install default-jre
      </kbd>
      <br/><br/>
      update server and install jre
      
      <br/><br/>
      <kbd>sudo apt-get install zookeeperd</kbd>
      <br/><br/>
      install zookeeper

      <br/><br/>
      <kbd>mkdir /home/kafka && sudo adduser --system --no-create-home --disabled-password --disabled-login kafka</kbd>
      <br/><br/>
      create user kafka
      <br/><br/>
      
      <kbd>
        cd /tmp/ <br/>
        &nbsp;wget http://apache.mirror.cdnetworks.com/kafka/2.3.0/kafka_2.12-2.3.0.tgz
      </kbd>

      <br/><br/>
      download kafka (<code><a href="https://kafka.apache.org/downloads" target="_blank">https://kafka.apache.org/downloads,</a> must be scala binary version</code>)

      <br/><br/>
      <kbd>
      sudo mkdir /opt/kafka <br/>
      &nbsp;sudo tar -xvzf kafka_2.12-2.3.0.tgz --directory /opt/kafka --strip-components 1
      </kbd>
      <br/><br/>
      create /opt/kafka directory and unzip kafka.tgz

      <br/><br/>
      <kbd>
      sudo mkdir /var/lib/kafka <br/>
      &nbsp;sudo mkdir /var/lib/kafka/data
      </kbd>
      <br/><br/>
      create directory for kafka message data

      <br/><br/>
      <kbd>
      sudo vi /opt/kafka/config/server.properties
      </kbd>
      <br/><br/>
      
      edit kafka server.properties
      
      <br/><br/>

      <kbd>
        log.dirs=/var/lib/kafka/data <br/>
        &nbsp;listeners=PLAINTEXT://:9092 <br/>
        &nbsp;log.retention.hours=72 <br/>
        &nbsp;delete.topic.enable=true <br/>
        &nbsp;allow.auto.create.topics=false</kbd>
      <br/><br/>
      
      change log.dirs value
      <br/><br/>
      
      <kbd>
      sudo chown -R kafka:nogroup /opt/kafka <br/>
      &nbsp;sudo chown -R kafka:nogroup /var/lib/kafka
      </kbd>
      <br/><br/>
      setting directory permission
      <br/><br/>
      
      <kbd>sudo vi /etc/systemd/system/kafka.service <br/><br/>

      &nbsp;[Unit] <br/>
      &nbsp;Description=High-available, distributed message broker <br/>
      &nbsp;After=network.target <br/>
      &nbsp;[Service] <br/>
      &nbsp;User=kafka <br/>
      &nbsp;ExecStart=/opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/server.properties <br/>
      &nbsp;[Install] <br/>
      &nbsp;WantedBy=multi-user.target <br/>
    </kbd>
      <br/>
      systemd service add
      <br/><br/>
      
      <kbd>
      sudo systemctl start kafka.service <br/>
      &nbsp;sudo systemctl enable kafka.service <br/><br/>
      &nbsp;/opt/kafka/bin/zookeeper-server-start.sh -daemon /opt/kafka/config/zookeeper.properties <br/>
      &nbsp;/opt/kafka/bin/kafka-server-start.sh -daemon /opt/kafka/config/server.properties
      </kbd>
      <br/><br/>
      start zookeeper and kafka

      <br/><br/>
      
      <kbd>
      /opt/kafka/bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test
      </kbd>
      <br/><br/>
      create kafka topic (test)
      <br/><br/>
      <kbd>/opt/kafka/bin/kafka-topics.sh --list --zookeeper localhost:2181</kbd>

      <br/><br/>
      kafka topic list
      <br/><br/>

      <kbd>/opt/kafka/bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test</kbd>
      
      <br/><br/>
      producing kafka message
      <br/><br/>
      <kbd>/opt/kafka/bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning</kbd>
      
      <br/><br/>consuming kafka message
      <br/><br/>
      <hr><br/>
      <h4>카프카 세부 설정 (server.properties)</h4>
      <br/>
      <ul>
        <li>
          <b>server basics</b>
          <ul>
            <li>
              <kbd>broker.id=0</kbd><br/>
              The id of the broker. This must be set to a unique integer for each broker.<br/>
              <b>카프카 호스트 이름과 broker.id 를 매핑한 숫자로 변경 (ex. peter-kafka001 -> broker.id=1)</b>
            </li><br/>
            <li>
              <kbd>log.dirs=/tmp/kafka-logs</kbd><br/>
              A comma seperated list of directories under which to store log files<br/>
              <b>카프카 로그가 저장될 디렉토리. 물리적 디스크가 여러개라면 콤마로 구분해서 입력</b>
            </li>
          </ul>
        </li>
        <br/>

        <li>
          <b>socket server settings</b>
          <ul>
            <li>
              <kbd>listeners=PLAINTEXT://:9092</kbd><br/>
              The address the socket server listens on<br/>
            </li><br/>
            <li>
              <kbd># advertised.listeners=PLAINTEXT://your.host.name:9092</kbd><br/>
              The address the socket server listens on<br/>
            </li><br/>
            <li>
              <kbd># advertised.listeners=PLAINTEXT://your.host.name:9092</kbd><br/>
              Hostname and port the broker will advertise to producers and consumers.<br/>
              If not set, it uses the value for "listeners" if configured.
            </li><br/>
            <li>
              <kbd># listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL</kbd><br/>
              Maps listener names to security protocols, the default is for them to be the same. See the config documentation for more details<br/>
            </li><br/>
            <li>
              <kbd>num.network.threads=3</kbd><br/>
              The number of threads that the server uses for receiving requests from the network and sending responses to the network<br/>
            </li><br/>
            <li>
              <kbd>num.io.threads=8</kbd><br/>
              The number of threads that the server uses for processing requests, which may include disk I/O<br/>
            </li><br/>
            <li>
              <kbd>socket.send.buffer.bytes=102400</kbd><br/>
              The send buffer (SO_SNDBUF) used by the socket server<br/>
            </li><br/>
            <li>
              <kbd>socket.receive.buffer.bytes=102400</kbd><br/>
              The receive buffer (SO_RCVBUF) used by the socket server<br/>
            </li><br/>
            <li>
              <kbd>socket.request.max.bytes=104857600</kbd><br/>
              The maximum size of a request that the socket server will accept (protection against OOM)<br/>
            </li>
          </ul>
        </li>
        <br/>

        <li>
          <b>log basics</b>
          <ul>
            <li>
              <kbd>log.dirs=/var/lib/kafka/data</kbd><br/>
              A comma separated list of directories under which to store log files
            </li><br/>

            <li>
              <kbd>num.partitions=1</kbd><br/>
              The default number of log partitions per topic. More partitions allow greater<br/>
              parallelism for consumption, but this will also result in more files across<br/>
              the brokers.
            </li><br/>
            <li>
              <kbd>num.recovery.threads.per.data.dir=1</kbd><br/>
              The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.<br/>
              This value is recommended to be increased for installations with data dirs located in RAID array.
            </li><br/>
          </ul>
        </li>

        <li>
          <b>internal topic settings</b>
          <ul>
            <li>
              <kbd>offsets.topic.replication.factor=1 <br/>
              &nbsp;transaction.state.log.replication.factor=1 <br/>
            &nbsp;transaction.state.log.min.isr=1</kbd><br/>
              A comma separated list of directories under which to store log files
            </li><br/>
          </ul>
        </li>

        <li>
          <b>log retention policy</b>
          <ul>
            <li>
              <kbd>log.retention.hours=168</kbd><br/>
              The minimum age of a log file to be eligible for deletion due to age
            </li><br/>
            <li>
              <kbd>#log.retention.bytes=1073741824</kbd><br/>
              A size-based retention policy for logs. Segments are pruned from the log unless the remaining<br/>
              segments drop below log.retention.bytes. Functions independently of log.retention.hours.
            </li><br/>
            <li>
              <kbd>log.segment.bytes=1073741824</kbd><br/>
              The maximum size of a log segment file. When this size is reached a new log segment will be created.
            </li><br/>
            <li>
              <kbd>log.retention.check.interval.ms=300000</kbd><br/>
              The interval at which log segments are checked to see if they can be deleted according to the retention policies
            </li><br/>
          </ul>
        </li>

        <li>
          <b>zookeeper</b>
          <ul>
            <li>
              <kbd>zookeeper.connection.timeout.ms=6000</kbd><br/>
              Timeout in ms for connecting to zookeeper
            </li><br/>
          </ul>
        </li>

        <li>
          <b>group coordinator settings</b>
          <ul>
            <li>
              <kbd>group.initial.rebalance.delay.ms=0</kbd><br/>
              The rebalance will be further delayed by the value of group.initial.rebalance.delay.ms as new members join the group, up to a maximum of max.poll.interval.ms.
            </li><br/>
          </ul>
        </li>
      </ul>

      <h4>카프카 세부 설정 (zookeeper.properties)</h4>
        
      <ul>
        <li>
          <b>zookeeper basics</b>
          <ul>
            <li>
              <kbd>dataDir=/tmp/zookeeper</kbd><br/>
              the directory where the snapshot is stored.
            </li><br/>
            <li>
              <kbd>clientPort=2181</kbd><br/>
              the port at which the clients will connect
            </li><br/>
            <li>
              <kbd>maxClientCnxns=0</kbd><br/>
              disable the per-ip limit on the number of connections since this is a non-production config
            </li><br/>
          </ul>
        </li>
      </ul>

      <h4>카프카 세부 설정 (producer.properties)</h4>
        
      <ul>
        <li>
          <b>producer basics</b>
          <ul>
            <li>
              <kbd>bootstrap.servers=localhost:9092</kbd><br/>
              list of brokers used for bootstrapping knowledge about the rest of the cluster
            </li><br/>
            <li>
              <kbd>compression.type=none</kbd><br/>
              specify the compression codec for all data generated: none, gzip, snappy, lz4, zstd
            </li><br/>
            <li>
              <kbd>#partitioner.class=</kbd><br/>
              name of the partitioner class for partitioning events; default partition spreads data randomly
            </li><br/>
            <li>
              <kbd>#request.timeout.ms=</kbd><br/>
              the maximum amount of time the client will wait for the response of a request
            </li><br/>
            <li>
              <kbd>#max.block.ms=</kbd><br/>
              how long `KafkaProducer.send` and `KafkaProducer.partitionsFor` will block for
            </li><br/>
            <li>
              <kbd>#linger.ms=</kbd><br/>
              the producer will wait for up to the given delay to allow other records to be sent so that the sends can be batched together
            </li><br/>
            <li>
              <kbd>#max.request.size=</kbd><br/>
              the maximum size of a request in bytes
            </li><br/>
            <li>
              <kbd>#batch.size=</kbd><br/>
              the default batch size in bytes when batching multiple records sent to a partition
            </li><br/>
            <li>
              <kbd>#buffer.memory=</kbd><br/>
              the total bytes of memory the producer can use to buffer records waiting to be sent to the server
            </li><br/>
          </ul>
        </li>
      </ul>

      <h4>카프카 세부 설정 (consumer.properties)</h4>
        
      <ul>
        <li>
          <b>consumer basics</b>
          <ul>
            <li>
              <kbd>bootstrap.servers=localhost:9092</kbd><br/>
              list of brokers used for bootstrapping knowledge about the rest of the cluster
            </li><br/>
            <li>
              <kbd>group.id=test-consumer-group</kbd><br/>
              consumer group id
            </li><br/>
            <li>
              <kbd>#auto.offset.reset=</kbd><br/>
              What to do when there is no initial offset in Kafka or if the current<br/>
              offset does not exist any more on the server: latest, earliest, none<br/><br/>
              
              새 소비자 시작 (new group.id) :이 경우 커밋 된 오프셋이 없으므로 소비자는 매개 변수 설정 auto.offset.reset에 따라 읽기 시작합니다.<br/>
              소비자 다시 시작 (group.id 재사용) :이 경우 소비자는 중단 된 지점에서 다시 시작합니다. 파라미터 설정 auto.offset.reset는 무시됩니다.<br/>
              따라서 시나리오 (1)의 경우 시작 위치 만 "구성"할 수 있습니다.<br/>
              시나리오 (2)의 경우 시작 위치가 "고정"되어 (즉, 항상 마지막 커밋 된 오프셋) 구성을 통해 변경할 수 없습니다.<br/>
              그러나 .seekToBeginning()를 처음 호출하기 전에 항상 .seekToEnd() 또는 poll()를 수행하고 전체 주제를 읽거나 주제의 끝에서 시작할 수 있습니다.<br/>
              .seekXX()를 호출하면 마지막으로 커밋 된 오프셋을 "덮어 쓰고"원하는 오프셋에서 소비를 시작할 수 있습니다.<br/>
              "offset parameter"를받는 seek()도 있으므로 소비를 시작하려는 오프셋을 지정할 수 있습니다.<br/>
            </li>
<br/>
          </ul>
        </li>
      </ul>
      
      <hr><br/>

      <h4>카프카 매니저</h4>
      <ul>
      <li>여러 개의 클러스터를 등록 및 관리</li>
      <li>클러스터 상태를 쉽게 확인</li>
      <li>파티션 리발란스</li>
      <li>토픽 생성 & 삭제</li>
      <li>토픽 리스트</li>
      <li>파티션 추가</li>
      <li>토픽 설정 업데이트</li>
    </ul>
      <br/>

      <kbd>apt-get install default-jdk</kbd>
      <br/><br/>
      install jdk for kafka manager
      <br/><br/>
      
      <kbd>cd /home/kafka/ <br/><br/>
      &nbsp;echo "deb https://dl.bintray.com/sbt/debian /" | sudo tee -a /etc/apt/sources.list.d/sbt.list <br/>
      &nbsp;sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 2EE0EA64E40A89B84B2DF73499E82A75642AC823 <br/>
      &nbsp;sudo apt-get update <br/>
      &nbsp;sudo apt-get install sbt <br/>
      </kbd>
      <br/>
      install sbt
      <br/><br/>

      <kbd>
      git clone https://github.com/yahoo/kafka-manager.git <br/>
      &nbsp;cd /home/kafka/kafka-manager <br/>
      &nbsp;./sbt clean dist </kbd>
      <br/><br/>
      this part is going to take some time as it has to download all the dependencies<br/>
      (<code><a href="https://github.com/yahoo/kafka-manager" target="_blank">https://github.com/yahoo/kafka-manager</a></code>)
      <br/><br/>
      
      <kbd>
      vi conf/application.conf <br/><br/>

      &nbsp;kafka-manager.zkhosts="localhost:2181" <br/>
      &nbsp;basicAuthentication.username="admin" <br/>
      &nbsp;basicAuthentication.password="password"</kbd>
      <br/><br/>
      change host and authentication, kafka-manager configuration
      <br/><br/>
    
      <kbd>cd target/universal <br/>
        &nbsp;unzip kafka-manager-2.0.0.2 && cd kafka-manager-2.0.0.2 <br/>
        &nbsp;bin/kafka-manager -Dconfig.file=conf/application.conf -Dhttp.port=8080 &</kbd>
      <br/><br/>
      unzip and start kafka-manager
      <br/><br/>

      <hr>
      <br/>
      
      <div>
        <h4>책에서 알려주는 '카프카 운영에 대한 Q&A'</h4>
        <br/>
        <h6>카프카 운영시 옵션을 변경하려면 어떻게 해야 하나요?</h6>
        <small>카프카의 옵션 설정은 카프카가 실행되면서 옵션 정보를 읽어오게 된다.<br/>운영 중인 상태에서 옵션을 변경해야 한다면, 원하는 옵션 설정을 변경한 후 클러스터 내 브로커를 1대씩 재시작해야 변경된 옵션이 적용된다.</small>

        <br/><br/>
        <h6>토픽이 삭제되지 않아요</h6>
        <small>토픽을 삭제하려면 설정 옵션 중 delete.topic.enable 이 true 로 되어 있어야 한다.</small>

        <br/><br/>
        <h6>디스크 사용량이 높아요. (또는) 디스크가 풀이에요.</h6>
        <small>카프카의 데이터 디렉토리에서 가장 사용량이 많은 토픽을 찾고 토픽의 보관주기를 변경하면 오래된 데이터가 삭제되어 디스크 공간을 확보할 수 있다.<br/>이러한 증상은 카프카 기본 설정이 7일 보관이므로 자주 발생하게 되는데, 가능하다면 log.retention.hours 옵션을 48시간 또는 72시간으로 변경하면 조금 더 효율적으로 운영할 수 있다.</small>

        <br/><br/>
        <h6>디스크를 추가하려면 어떻게 해야하나요?</h6>
        <small>브로커 옵션 설정에서 log.dirs 옵션에 추가한 디스크 경로를 추가한 후 브로커를 재시작하면 된다.</small>

        <br/><br/>
        <h6>OS 점검을 하려면 어떻게 해야하나요?</h6>
        <small>클러스터에서 브로커 1대를 제외한 후 OS 점검 등을 진행하면 된다.</small>

        <br/><br/>
        <h6>토픽에 전송한 메시지가 제대로 들어갔는지 어떻게 확인하나요?</h6>
        <small>컨슈머로 토픽의 메시지를 가져와서 확인해야 하는데, 프로그래밍 오류 등으로 메시지를 가져오지 못하는 경우가 있을 수 있다.<br/>가장 정확하게 확인하는 방법은 콘솔 컨슈머를 이용해 해당 토픽의 메시지를 가져오는 것이다.</small>

        <br/><br/>
        <h6>주키퍼를 설치할 때 아파치 버전과 카프카에 포함된 버전 중 어느 것이 더 좋은가요?</h6>
        <small>주키퍼는 카프카의 노드 관리와 메타 정보를 저장하는 용도로 사용한다.<br/>두가지 모두 해당 기능을 제공하는 데는 아무런 문제가 없으니 사용자 편의에 따라 선택해 사용하면 된다.</small>

        <br/><br/>
        <h6>주키퍼에서 제공하는 명령어는 쓰기가 불편한데, 앙상블 전체의 상태정보를 볼 수 있는 간단한 툴은 없나요?</h6>
        <small>zktop 이라는 툴을 이용하면 CLI 상태에서 한눈에 주키퍼 앙상블 상태를 확인할 수 있다.</small>

        <br/><br/>
        <h6>카프카 버전 업그레이드는 어떻게 하나요?</h6>
        <small>두가지 방법이 있다.<br/>1대씩 내렸다가 올리는 롤링 업그레이드와 모든 브로커를 종료한 후 새로운 버전으로 실행하는 방법이다.</small>

        <br/><br/>
        <h6>롤링 업그레이드는 어떻게 하나요?</h6>
        <small>브로커 1대씩 새 버전을 설치한 후 카프카 환경설정 파일인 server.properties 에 다음과 같은 코드 두 줄을 추가한 후 재시작한다.
        
        <br/><br/>
        inter.broker.protocol.version=현재 카프카 버전<br/>
        log.message.format.version=현재 카프카 버전

        </small>

        <br/><br/>
        <h6>카프카 버전을 업그레이드할 때 주의해야 할 사항은 없나요?</h6>
        <small>버전이 업그레이드되면서 기존 버전의 환경설정 값이 변경되는 경우가 있다.<br/>카프카 버전 업그레이드 이후 메시지 전송과 수신 또는 연결 등의 문제가 발생할 수 있으니 클라이언트 버전 호환성도 체크하는 것이 좋다.</small>

        <br/><br/>
        <h6>카프카 버전을 업그레이드할 때 주키퍼도 함께 버전 업그레이드를 해야 하나요?</h6>
        <small>주키퍼와 카프카는 별도의 어플리케이션이므로 카프카 버전 업그레이드를 한다고 해서 반드시 주키퍼 버전 업그레이드도 함께 해야하는 것은 아니다.<br/>일반적으로 카프카의 버전 업그레이드만 수행한다.</small>

        <br/><br/>
        <h6>자바의 힙 사이즈는 물리 메모리의 절반 정도로 잡는데, 카프카는 어떻게 설정하는 것이 좋나요?</h6>
        <small>카프카의 경우 힙 사이즈는 5~6 GB 정도로만 설정하고 남아 있는 메모리는 페이지 캐시로 사용하기를 권장한다.</small>

        <br/><br/>
      </div>
      <hr>
      <br/>

    </div>
  </section>

<a href="#" class="scrollup"><i class="icon-angle-up icon-square icon-bgdark icon-2x"></i></a>
<script src="../js/jquery.js"></script>
<script src="../js/bootstrap.js"></script>

</body>
</html>
